{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/happylittle7/TAICA_Generative-AI-Text-and-Image-Synthesis-Principles-and-Practice/blob/main/NTNU_41247032S_%E8%B3%87%E5%B7%A5116_%E5%90%B3%E4%BF%8A%E5%BB%B7_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkYdA5re0Ave"
      },
      "source": [
        "## STEP 1 讀入套件\n",
        "\n",
        "先一樣讀入一些基本的套件，因為最後的使用者介面是Web app，會用到Gradio，故在這邊先用pip安裝。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "fdIz5z2klW4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "接著安裝老師在上課時提到的基本四件套"
      ],
      "metadata": {
        "id": "S4ZAa5XDfz62"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEq2NFpF0Avf"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# 標準數據分析、畫圖套件\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# 神經網路方面\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# 互動設計用\n",
        "from ipywidgets import interact_manual\n",
        "\n",
        "# 神速打造 web app 的 Gradio\n",
        "import gradio as gr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVSdolkn0Avg"
      },
      "source": [
        "## STEP 2 讀入資料集"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0UEBwg60Avg"
      },
      "source": [
        "讀取上課提到的MNIST資料集，把它存到程式裡"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKuZWeVy0Avg"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnTUn8540Avi"
      },
      "source": [
        "## STEP 3 檢查資料及內容\n",
        "\n",
        "利用老師上課寫好的函式 show_xy 來確認讀到的資料是不是符合我們的預期。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5RwWLHx0Avi"
      },
      "source": [
        "def show_xy(n=0):\n",
        "    ax = plt.gca()\n",
        "    X = x_train[n]\n",
        "    plt.xticks([], [])\n",
        "    plt.yticks([], [])\n",
        "    plt.imshow(X, cmap = 'Greys')\n",
        "    print(f'本資料 y 給定的答案為: {y_train[n]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfBAIU280Avj"
      },
      "source": [
        "interact_manual(show_xy, n=(0,59999));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "可以看到對於每筆n，存到的都有對應不同的手寫數字資料"
      ],
      "metadata": {
        "id": "2vXaGU8siav1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOPj5Mh50Avk"
      },
      "source": [
        "## STEP 4 把資料進行 reshape\n",
        "因為我們現在要用的標準神經網路只能吃「平平的」資料，所以先用reshape對資料進行預處理（轉成784長的向量形式）\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT7oXt8B0Avk"
      },
      "source": [
        "x_train = x_train.reshape(60000, 784)/255\n",
        "x_test = x_test.reshape(10000, 784)/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQmajlcm0Avl"
      },
      "source": [
        "## STEP 5 對資料進行 one-hot encoding\n",
        "因為０~9是有有序、連續性的，為了避免其干擾到我們對手寫數字辨識的訓練，我們對其進行one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i22oLVf0Avl"
      },
      "source": [
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9mWLghi0Avl"
      },
      "source": [
        "試著來看轉換過後的資料，可以發現資料真的被 one hot-encoding 了"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxkwtCy-0Avm"
      },
      "source": [
        "n = 3\n",
        "y_train[n]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m41UZZdF0Avm"
      },
      "source": [
        "## STEP 6 建構神經網路\n",
        "\n",
        "我打算使用Sequential一層一層新增神經元。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_fx6jw80Avm"
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "我先試著將原本上課的模型層數、神經元個數加多"
      ],
      "metadata": {
        "id": "nN3GTuy97CHp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrBnZ3Xw0Avn"
      },
      "source": [
        "model.add(Dense(512, input_dim=784, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5znBU0DV0Avo"
      },
      "source": [
        "## STEP 7 組裝神經網路\n",
        "\n",
        "在這邊 loss function, 一樣選擇 `mse`，optimizer, 同樣使用標準的 SGD ， 設 learning rate 為 0.1。\n",
        "\n",
        "本次試驗觀察如果每層神經元數、層數變多，對最終結果是否有明顯影響。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGLgh8Gz0Avo"
      },
      "source": [
        "model.compile(loss='mse', optimizer=SGD(learning_rate=0.087), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xf9ykvbJ0Avo"
      },
      "source": [
        "## 4. STEP 8 確認神經元架構"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yJJowZE0Avp"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5VHPpfd0Avp"
      },
      "source": [
        "## STEP 9 訓練神經網路\n",
        "\n",
        "這次以batch_size=100，跑10次迭代進行訓練，並且把過程記錄下來，方便等等分析，另外將測試資料且十分之二作為驗證集。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jwuUx4a0Avq"
      },
      "source": [
        "history = model.fit(x_train, y_train, batch_size=100, epochs=10, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6ykAvga0Avq"
      },
      "source": [
        "## STEP 10 評估結果\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9c1E_Cj0Avq"
      },
      "source": [
        "loss, acc = model.evaluate(x_test, y_test)\n",
        "print(f\"測試資料正確率 {acc*100:.2f}%\")\n",
        "print('loss:', loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "在這邊將訓練過程視覺化，更清楚訓練時模型的表現。"
      ],
      "metadata": {
        "id": "YRtSA3eOBhqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'], label='Train accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Valid accuracy')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training process')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jCu9fFR__bIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "在做這份作業時，可以發現正確率比範例程式碼的正確率（0.8952999711036682）高，故看起來調大神經元數和層數是個可以深究的策略。"
      ],
      "metadata": {
        "id": "3Ej9fUvt_Bu0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWK0fgKgCHa7"
      },
      "source": [
        "##STEP 11 用 Gradio 來展示\n",
        "這邊是方便自己可以快速做測試。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_image(inp):\n",
        "    # 圖在 inp[\"layers\"][0]\n",
        "    image = np.array(inp[\"layers\"][0], dtype=np.float32)\n",
        "    image = image.astype(np.uint8)\n",
        "\n",
        "    # 轉成 PIL 格式\n",
        "    image_pil = Image.fromarray(image)\n",
        "\n",
        "    # Alpha 通道設為白色, 再把圖從 RGBA 轉成 RGB\n",
        "    background = Image.new(\"RGB\", image_pil.size, (255, 255, 255))\n",
        "    background.paste(image_pil, mask=image_pil.split()[3]) # 把圖片粘貼到白色背景上，使用透明通道作為遮罩\n",
        "    image_pil = background\n",
        "\n",
        "    # 轉換為灰階圖像\n",
        "    image_gray = image_pil.convert(\"L\")\n",
        "\n",
        "    # 將灰階圖像縮放到 28x28, 轉回 numpy array\n",
        "    img_array = np.array(image_gray.resize((28, 28), resample=Image.LANCZOS))\n",
        "\n",
        "    # 配合 MNIST 數據集\n",
        "    img_array = 255 - img_array\n",
        "\n",
        "    # 拉平並縮放\n",
        "    img_array = img_array.reshape(1, 784) / 255.0\n",
        "\n",
        "    return img_array"
      ],
      "metadata": {
        "id": "YCDldfE4eVh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recognize_digit(inp):\n",
        "    img_array = resize_image(inp)\n",
        "    prediction = model.predict(img_array).flatten()\n",
        "    labels = list('0123456789')\n",
        "    return {labels[i]: float(prediction[i]) for i in range(10)}"
      ],
      "metadata": {
        "id": "QUejwCO9S7R4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITOFueb5KSBD"
      },
      "source": [
        "iface = gr.Interface(\n",
        "    fn=recognize_digit,\n",
        "    inputs=gr.Sketchpad(),\n",
        "    outputs=gr.Label(num_top_classes=3),\n",
        "    title=\"MNIST 手寫辨識\",\n",
        "    description=\"請在畫板上繪製數字\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True, debug=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 12 建構、訓練模型 2\n",
        "我後來去翻書，另外嘗試做了另一個模型，中間用到了一些新的方式：\n",
        "\n",
        "\n",
        "*   Dropout：避免over fitting，模仿人類學習那樣沒辦法百分之百吸收的效果\n",
        "*   LeakyReLU： 和老師使用的ReLU激活函數不一樣。如果使用ReLU的話，當輸入值為負時，它的輸出永遠是 0，這樣會導致神經元永遠不更新權重。因此採用LeakyReLU，他的負數區域允許一些小的梯度（α=0.1），這樣可以讓梯度流動。\n"
      ],
      "metadata": {
        "id": "dMxrT-v3Anj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(256, input_dim=784))\n",
        "model.add(LeakyReLU(negative_slope=0.1))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(128))\n",
        "model.add(LeakyReLU(negative_slope=0.1))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(64))\n",
        "model.add(LeakyReLU(negative_slope=0.1))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(32))\n",
        "model.add(LeakyReLU(negative_slope=0.1))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=SGD(learning_rate=0.1), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "VKAWGeZ3AnTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, batch_size=100, epochs=100, validation_split=0.2)"
      ],
      "metadata": {
        "id": "oUQY5JiCCYQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(x_test, y_test)\n",
        "print(f\"測試資料正確率 {acc*100:.2f}%\")\n",
        "print('loss:', loss)"
      ],
      "metadata": {
        "id": "8Rn0juEHbnPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'], label='Train accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Valid accuracy')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training process')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dNY9WI8QbsG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "經過訓練後，可以發現準確性有大幅上升，訓練大約在第20次迭代後正確性即差不多固定。"
      ],
      "metadata": {
        "id": "-NM5wDg8rJD2"
      }
    }
  ]
}